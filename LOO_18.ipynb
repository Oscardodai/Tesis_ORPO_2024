{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMra4op1dngozbjZS1rmp9O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aGz3L6v9A7WL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724330680691,"user_tz":360,"elapsed":241,"user":{"displayName":"oscar perez","userId":"03418065250002973875"}},"outputId":"59327720-e25c-4f17-dbc6-c853558aea9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precisiones individuales: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]\n","Precisión promedio: 0.8181818181818182\n","Los pesos finales son: [ 0.14928308 -0.87188472  1.17302282  0.58105681  0.82001139]\n","Valor del bias: 0.1492830804411921\n"]}],"source":["import numpy as np\n","\n","### Entrenamiento del perceptrón utilizando el método leave one out considerando los 18 sujetos de prueba\n","\n","class Perceptron:\n","    def __init__(self, num_inputs=4, learning_rate=0.01):\n","        self.weights = np.random.rand(num_inputs + 1)  # +1 para el bias\n","        self.learning_rate = learning_rate\n","\n","    def predict(self, inputs):\n","        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n","        return 1 if summation > 0 else 0  # 1: sano, 0: enfermo\n","\n","    def train(self, training_inputs, labels, epochs=10):\n","        for _ in range(epochs):\n","            for inputs, label in zip(training_inputs, labels):\n","                prediction = self.predict(inputs)\n","                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n","                self.weights[0] += self.learning_rate * (label - prediction)\n","\n","# Datos de ejemplo\n","training_inputs = np.array([\n","    [146.03, 483.4086, 6.7258, 38.5611],\n","    [130.5, 340.6822, 5.6472, 33.5022],\n","    [140.42, 610.0028, 10.592, 58.4126],\n","    [122.6, 225.1592, 6.3824, 34.2609],\n","    [176.5, 167.6763, 7.1915, 41.6415],\n","    [118.33, 101.5687, 6.0578, 18.6116],\n","    [121.27, 257.5573, 4.8765, 28.9913],\n","    [207.13, 352.6804, 11.393, 54.6367],\n","    [63.89, 79.4307, 3.6416, 16.8815],\n","    [107.71, 139.3319, 5.9087, 25.8553 ],\n","    [63.2739, 36.3969, 2.4914, 10.9656],\n","    [65.39, 15.8628, 4.2235, 10.7561],\n","    [91.82, 61.7602, 4.9526, 13.5222],\n","    [63.91, 82.9967, 3.0201, 7.1415],\n","    [157.37, 131.5444, 6.0522, 26.6659],\n","    [63.89, 84.2240, 3.2629, 7.7638], # estos datos corresponden a la amputada 1 y se etiquetó como sana\n","    [10.986, 11.3238, 0.8563, 1.8565],\n","    [22.33, 13.9855, 0.8319, 2.7486],\n","    [18.163, 9.1734, 0.1134, 1.1127], #datos de Q con eqtiqueta de enfermo\n","    [17.521, 10.4455, 0.1793, 1.4127],\n","    [22.33, 13.9855, 0.8319, 2.7486],\n","    [22.33, 13.9855, 0.8319, 2.7486]\n","])\n","labels = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])\n","\n","# Entrenamiento con Leave-One-Out\n","num_samples = len(training_inputs)\n","accuracies = []\n","final_weights = []\n","\n","for i in range(num_samples):\n","    # Dividir los datos en entrenamiento y prueba\n","    X_train = np.delete(training_inputs, i, axis=0)\n","    y_train = np.delete(labels, i)\n","    X_test = training_inputs[i].reshape(1, -1)\n","    y_test = labels[i]\n","\n","    # Crear y entrenar un nuevo perceptrón en cada iteración\n","    perceptron = Perceptron()\n","    perceptron.train(X_train, y_train)\n","\n","    # Evaluar el modelo en el dato excluido\n","    prediction = perceptron.predict(X_test)\n","    accuracy = 1 if prediction == y_test else 0\n","    accuracies.append(accuracy)\n","\n","    # Guardar los pesos finales (después de una sola iteración LOO)\n","    final_weights.append(perceptron.weights.copy())\n","\n","# Calcular los pesos promedios\n","average_weights = np.mean(final_weights, axis=0)\n","\n","# Resultados\n","print(\"Precisiones individuales:\", accuracies)\n","print(\"Precisión promedio:\", np.mean(accuracies))\n","print(\"Los pesos finales son:\", average_weights)\n","print(\"Valor del bias:\", average_weights[0])"]}]}